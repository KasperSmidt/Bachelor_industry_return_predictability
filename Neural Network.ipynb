{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b11b50-af72-4fe6-bd0a-137962086d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reduce display precision on numpy arrays\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "df = pd.read_csv('C:/Users/Computer/Documents/bachelor/dataset.csv')\n",
    "pd.options.mode.chained_assignment=None\n",
    "df['csp'][637:]  = df['csp'][0:638].mean()\n",
    "\n",
    "df['Index'] = pd.to_numeric(df['Index'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd796e-ffaf-48de-939f-3a5c9aeae4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dda7d0-1fb7-4dc3-8c51-b0de3a7fd9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-30].values\n",
    "Y = df.iloc[:, -30:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04edac70-0475-4bba-bc65-cf017a145a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = df.columns[1:18]\n",
    "target_names = df.columns[-30:] \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_df = df[feature_names]\n",
    "Y_df = df[target_names]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_df = pd.DataFrame(scaler.fit_transform(X_df), columns=X_df.columns)\n",
    "\n",
    "data = pd.concat([Y_df, X_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625136c7-ba9b-40d7-8308-9756b952bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_nn(hidden_layers, neurons, dropout_rate, learning_rate, alpha):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=17, kernel_initializer='normal', activation='relu', kernel_regularizer='l2'))\n",
    "\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu', kernel_regularizer='l2'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(30, activation='linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffea2d-4c64-4122-b51b-794e5a35438f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initial_hyperparameter_tuning(train, y_keys, model_config):\n",
    "    X_train = train.drop(y_keys, axis=1)\n",
    "    y_train = train[y_keys]\n",
    "\n",
    "    time_series_cv = TimeSeriesSplit(n_splits=model_config[\"tscv_splits\"])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    param_grid = {\n",
    "        \"hidden_layers\": [1, 2, 3],\n",
    "        \"neurons\": [16, 32, 64],\n",
    "        \"dropout_rate\": [0.1, 0.2],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \"alpha\": [0.01, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(KerasRegressor(model=create_nn, epochs=100, batch_size=10, verbose=0, alpha=0.01, learning_rate=0.01, dropout_rate=0.1, neurons=16, hidden_layers=1),\n",
    "                               param_grid, cv=time_series_cv, scoring=\"neg_mean_squared_error\", n_jobs=1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c76108-5f23-453e-9270-70acad21d376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nn_tuned(train, test, y_keys, best_params):\n",
    "    X_train = train.drop(y_keys, axis=1)\n",
    "    X_test = test.drop(y_keys, axis=1)\n",
    "    y_train = train[y_keys]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = create_nn(best_params[\"hidden_layers\"], best_params[\"neurons\"], best_params[\"dropout_rate\"],\n",
    "                      best_params[\"learning_rate\"], best_params[\"alpha\"])\n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "    y_hat = pd.DataFrame(model.predict(X_test_scaled), index=test.index, columns=y_keys)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    \"tscv_splits\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a9fa5-dbee-4bb7-a0cb-e46d82c7bff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "train_start_size = 200\n",
    "initial_train = data.iloc[:train_start_size]\n",
    "\n",
    "best_params = initial_hyperparameter_tuning(initial_train, Y_df.columns, model_config)\n",
    "\n",
    "Actuals = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Forecasts = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Forecast_Errors = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "MAE = {}\n",
    "MSE = {}\n",
    "R2 = {}\n",
    "\n",
    "# Expanding window loop\n",
    "for t in range(train_start_size, len(data) - 1):\n",
    "    train = data.iloc[:t]\n",
    "    test = data.iloc[t : t + 1]\n",
    "\n",
    "    preds = nn_tuned(train, test, Y_df.columns, best_params)\n",
    "\n",
    "    for col in Y_df.columns:\n",
    "        Forecasts[col] = pd.concat([Forecasts[col], preds[col]])\n",
    "        Actuals[col] = pd.concat([Actuals[col], test[col]])\n",
    "        Forecast_Errors[col] = pd.concat([Forecast_Errors[col], test[col] - preds[col]])\n",
    "\n",
    "    # Print progress every 25 data points\n",
    "    if t % 25 == 0:\n",
    "        print(f\"Progress: {t}/{len(data) - 1}\")\n",
    "\n",
    "# Calculate MAE and MSE for each target variable\n",
    "for col in Y_df.columns:\n",
    "    MAE[col] = mean_absolute_error(Actuals[col], Forecasts[col])\n",
    "    MSE[col] = mean_squared_error(Actuals[col], Forecasts[col])\n",
    "    R2[col] = r2_score(Actuals[col], Forecasts[col])\n",
    "\n",
    "for col in Y_df.columns:\n",
    "    print(f\"Actuals for {col}:\")\n",
    "    print(Actuals[col])\n",
    "    print(f\"Forecasts for {col}:\")\n",
    "    print(Forecasts[col])\n",
    "    print(f\"Forecast Errors for {col}:\")\n",
    "    print(Forecast_Errors[col])\n",
    "    print(f\"Mean Absolute Error for {col}: {MAE[col]}\")\n",
    "    print(f\"Mean Squared Error for {col}: {MSE[col]}\")\n",
    "    print(f\"R-squared for {col}: {R2[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86725c-8c01-4c21-9613-b0c3dd0b5f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d459c-d704-4167-a704-2a086d856e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters:\")\n",
    "for y_key in best_params.keys():\n",
    "    print(y_key, \":\", best_params[y_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2f760-6e2e-4c74-b2b3-e563e08b8b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a09bc-192a-44eb-b1b2-4c456df9cbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_metrics = pd.DataFrame(columns=['Industry', 'MAE', 'MSE', 'R2'])\n",
    "\n",
    "# put existing performance metrics in to df\n",
    "for i, col in enumerate(Y_df.columns):\n",
    "    performance_metrics.loc[i, 'Industry'] = col\n",
    "    performance_metrics.loc[i, 'MAE'] = MAE[col]\n",
    "    performance_metrics.loc[i, 'MSE'] = MSE[col]\n",
    "    performance_metrics.loc[i, 'R2'] = R2[col]\n",
    "\n",
    "# Calculate the mean across all industries and add it \n",
    "mean_mae = performance_metrics['MAE'].mean()\n",
    "mean_mse = performance_metrics['MSE'].mean()\n",
    "mean_r2 = performance_metrics['R2'].mean()\n",
    "\n",
    "performance_metrics.loc[len(Y_df.columns), ['Industry', 'MAE', 'MSE', 'R2']] = ['Mean', mean_mae, mean_mse, mean_r2]\n",
    "\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8feef3b-2e66-47a3-83ee-ff44a1ba64b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6aaa08-42da-497a-8c88-d20deb90706b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Historical_Mean_In_Sample_MSE = {}\n",
    "\n",
    "# Calculate in-sample historical mean forecasts and MSE for each target variable\n",
    "for col in Y_df.columns:\n",
    "    in_sample_data = Y_df.iloc[:train_start_size]  # Use only in-sample data\n",
    "    in_sample_historical_mean = in_sample_data[col].mean()\n",
    "    in_sample_historical_mean_forecast = pd.Series([in_sample_historical_mean] * len(in_sample_data), index=in_sample_data[col].index)\n",
    "    \n",
    "    Historical_Mean_In_Sample_MSE[col] = mean_squared_error(in_sample_data[col], in_sample_historical_mean_forecast)\n",
    "    \n",
    "mean_in_sample_mse = sum(Historical_Mean_In_Sample_MSE.values()) / len(Historical_Mean_In_Sample_MSE)\n",
    "\n",
    "# Create a DataFrame with columns for each performance metric\n",
    "results_df = pd.DataFrame(columns=[\"Historical_Mean_In_Sample_MSE\"])\n",
    "\n",
    "# in the DataFrame we put in the in-sample MSE results\n",
    "for col in Y_df.columns:\n",
    "    results_df.loc[col] = [Historical_Mean_In_Sample_MSE[col]]\n",
    "\n",
    "# Calculate and add the mean in-sample MSE to the DataFrame\n",
    "results_df.loc[\"Mean\"] = [mean_in_sample_mse]\n",
    "\n",
    "R2_OS_FFN = {}\n",
    "for col in Y_df.columns:\n",
    "    R2_OS_FFN[col] = 1 - (performance_metrics.set_index(\"Industry\").loc[col, \"MSE\"] / results_df.loc[col, \"Historical_Mean_In_Sample_MSE\"])\n",
    "\n",
    "# Create a DataFrame to store the out-of-sample R-squared results\n",
    "out_of_sample_predictability_df = pd.DataFrame(columns=[\"Industry\", \"R2_OS_FFN\"])\n",
    "\n",
    "# Populate the DataFrame with the out-of-sample R-squared values\n",
    "for i, col in enumerate(Y_df.columns):\n",
    "    out_of_sample_predictability_df.loc[i, \"Industry\"] = col\n",
    "    out_of_sample_predictability_df.loc[i, \"R2_OS_FFN\"] = R2_OS_FFN[col]\n",
    "\n",
    "# Calculate the mean out-of-sample R-squared across all industries and add it to the DataFrame\n",
    "mean_r2_os = out_of_sample_predictability_df[\"R2_OS_FFN\"].mean()\n",
    "out_of_sample_predictability_df.loc[len(Y_df.columns), [\"Industry\", \"R2_OS_FFN\"]] = [\"Mean\", mean_r2_os]\n",
    "\n",
    "# Display the out-of-sample predictability DataFrame\n",
    "print(out_of_sample_predictability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff97461-b5a2-46a2-ba06-037dfd9161db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
