{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f73cc1-bd85-4a1b-9c07-1d8255e63a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reduce display precision on numpy arrays\n",
    "np.set_printoptions(precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110be1d4-87d8-4913-a605-744cadc95993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Computer/Documents/bachelor/dataset.csv')\n",
    "pd.options.mode.chained_assignment=None\n",
    "df['csp'][637:]  = df['csp'][0:638].mean()\n",
    "\n",
    "df['Index'] = pd.to_numeric(df['Index'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1256396-6c75-41f8-8c20-46dbcedcaa48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43e563-f5e2-46d8-a357-66c206193570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-30].values\n",
    "Y = df.iloc[:, -30:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c5d78-122b-4d56-af3c-9b3310868a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = df.columns[1:18]\n",
    "target_names = df.columns[-30:]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_df = df[feature_names]\n",
    "Y_df = df[target_names]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_df = pd.DataFrame(scaler.fit_transform(X_df), columns=X_df.columns)\n",
    "\n",
    "data = pd.concat([Y_df, X_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40936c9-bd24-46bd-8b1e-cec6f5fc0ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "industry_names = Y_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764a6ec-7f07-466b-94f7-9521750841d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "train_start_size = 200\n",
    "\n",
    "# Initialize empty dictionaries to store results\n",
    "Actuals = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Historical_Mean_Forecasts = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Historical_Mean_Forecast_Errors = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Historical_Mean_MAE = {}\n",
    "Historical_Mean_MSE = {}\n",
    "Historical_Mean_R2 = {}\n",
    "\n",
    "# Expanding window loop\n",
    "for t in range(train_start_size, len(Y_df) - 1):\n",
    "    train = Y_df.iloc[:t]\n",
    "    test = Y_df.iloc[t : t + 1]\n",
    "\n",
    "    for col in Y_df.columns:\n",
    "        historical_mean = train[col].mean()\n",
    "        historical_mean_forecast = pd.Series([historical_mean], index=test[col].index)\n",
    "        \n",
    "        Historical_Mean_Forecasts[col] = pd.concat([Historical_Mean_Forecasts[col], historical_mean_forecast])\n",
    "        Actuals[col] = pd.concat([Actuals[col], test[col]])\n",
    "        Historical_Mean_Forecast_Errors[col] = pd.concat([Historical_Mean_Forecast_Errors[col], test[col] - historical_mean_forecast])\n",
    "        \n",
    "    # Print progress every 25 data points\n",
    "    if t % 25 == 0:\n",
    "        print(f\"Progress: {t}/{len(Y_df) - 1}\")\n",
    "\n",
    "# Calculate MAE, MSE, and R-squared for each target variable\n",
    "for col in Y_df.columns:\n",
    "    Historical_Mean_MAE[col] = mean_absolute_error(Actuals[col], Historical_Mean_Forecasts[col])\n",
    "    Historical_Mean_MSE[col] = mean_squared_error(Actuals[col], Historical_Mean_Forecasts[col])\n",
    "    Historical_Mean_R2[col] = r2_score(Actuals[col], Historical_Mean_Forecasts[col])\n",
    "\n",
    "for col in Y_df.columns:\n",
    "    print(f\"Actuals for {col}:\")\n",
    "    print(Actuals[col])\n",
    "    print(f\"Historical Mean Forecasts for {col}:\")\n",
    "    print(Historical_Mean_Forecasts[col])\n",
    "    print(f\"Historical Mean Forecast Errors for {col}:\")\n",
    "    print(Historical_Mean_Forecast_Errors[col])\n",
    "    print(f\"Historical Mean MAE for {col}: {Historical_Mean_MAE[col]}\")\n",
    "    print(f\"Historical Mean MSE for {col}: {Historical_Mean_MSE[col]}\")\n",
    "    print(f\"Historical Mean R-squared for {col}: {Historical_Mean_R2[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f3413-479b-4b73-bb1d-3dfa0dece3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_metrics = pd.DataFrame(columns=['Industry', 'MAE', 'MSE', 'R2'])\n",
    "\n",
    "# put existing performance metrics in to dataframe.\n",
    "for i, col in enumerate(Y_df.columns):\n",
    "    performance_metrics.loc[i, 'Industry'] = col\n",
    "    performance_metrics.loc[i, 'MAE'] = Historical_Mean_MAE[col]\n",
    "    performance_metrics.loc[i, 'MSE'] = Historical_Mean_MSE[col]\n",
    "    performance_metrics.loc[i, 'R2'] = Historical_Mean_R2[col]\n",
    "\n",
    "# Calculate the mean across all industries and add it\n",
    "mean_mae = performance_metrics['MAE'].mean()\n",
    "mean_mse = performance_metrics['MSE'].mean()\n",
    "mean_r2 = performance_metrics['R2'].mean()\n",
    "\n",
    "performance_metrics.loc[len(Y_df.columns), ['Industry', 'MAE', 'MSE', 'R2']] = ['Mean', mean_mae, mean_mse, mean_r2]\n",
    "\n",
    "# Display the performance metrics DataFrame\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01031ff3-77bc-48df-8eee-d33de4ff803c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Historical_Mean_In_Sample_MSE = {}\n",
    "\n",
    "# Calculate in-sample historical mean forecasts and MSE for each target variable\n",
    "for col in Y_df.columns:\n",
    "    in_sample_data = Y_df.iloc[:train_start_size]  # Use only in-sample data\n",
    "    in_sample_historical_mean = in_sample_data[col].mean()\n",
    "    in_sample_historical_mean_forecast = pd.Series([in_sample_historical_mean] * len(in_sample_data), index=in_sample_data[col].index)\n",
    "    \n",
    "    # Calculate in-sample MSE\n",
    "    Historical_Mean_In_Sample_MSE[col] = mean_squared_error(in_sample_data[col], in_sample_historical_mean_forecast)\n",
    "\n",
    "# Print in-sample MSE results\n",
    "for col in Y_df.columns:\n",
    "    print(f\"Historical Mean In-Sample MSE for {col}: {Historical_Mean_In_Sample_MSE[col]}\")\n",
    "\n",
    "# Calculate the mean in-sample MSE\n",
    "mean_in_sample_mse = sum(Historical_Mean_In_Sample_MSE.values()) / len(Historical_Mean_In_Sample_MSE)\n",
    "\n",
    "print(f\"Mean In-Sample MSE for Historical Mean Model: {mean_in_sample_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828333c-3bbf-48e2-b0ed-c7665fac66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef3944-1e5c-4e48-9fde-7c06d3a2a2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with columns for each performance metric\n",
    "results_df = pd.DataFrame(columns=[\"Historical_Mean_In_Sample_MSE\"])\n",
    "\n",
    "# Populate the DataFrame with in-sample MSE results\n",
    "for col in Y_df.columns:\n",
    "    results_df.loc[col] = [Historical_Mean_In_Sample_MSE[col]]\n",
    "\n",
    "# Calculate and add the mean in-sample MSE \n",
    "results_df.loc[\"Mean\"] = [mean_in_sample_mse]\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8f7b3-a296-49ae-96ae-30c8c8997006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40b8f3b-77e7-416e-baba-1e6b82fb44ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "X = df.iloc[:, 1:-30].values\n",
    "Y = df.iloc[:, -30:].values\n",
    "\n",
    "feature_names = df.columns[1:18]  # Extract the feature names (columns 1 to 17)\n",
    "target_names = df.columns[-30:]  # Extract the target names (last 30 columns)\n",
    "\n",
    "X_df = df[feature_names]\n",
    "Y_df = df[target_names]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_df = pd.DataFrame(scaler.fit_transform(X_df), columns=X_df.columns)\n",
    "\n",
    "data = pd.concat([Y_df, X_df], axis=1)\n",
    "\n",
    "train_start_size = 200\n",
    "coefficients_list = []\n",
    "\n",
    "for target in target_names:\n",
    "    train_X = X_df.iloc[:train_start_size]\n",
    "    train_Y = Y_df.iloc[:train_start_size][target]\n",
    "\n",
    "    ols_model = LinearRegression().fit(train_X, train_Y)\n",
    "    coefficients = ols_model.coef_\n",
    "    coefficients_list.append(coefficients)\n",
    "\n",
    "coefficients_df = pd.DataFrame(coefficients_list, columns=feature_names, index=target_names)\n",
    "\n",
    "print(coefficients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14510f4-efbc-48e6-916d-badffcd62d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "\n",
    "def hac_standard_errors(X, y):\n",
    "    model = sm.OLS(y, sm.add_constant(X)).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "    return model.bse[1:] \n",
    "\n",
    "hac_se = {}\n",
    "for col in Y_df.columns:\n",
    "    X_train = data[feature_names]\n",
    "    y_train = data[col]\n",
    "    hac_se[col] = hac_standard_errors(X_train, y_train)\n",
    "\n",
    "hac_se_df = pd.DataFrame(hac_se, index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338d553-25ae-44fc-83a2-d1d0ffcba1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def hypothesis_tests(X, y, feature_names, standard_errors, alpha=0.05):\n",
    "    model = sm.OLS(y, sm.add_constant(X)).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "    t_stats = model.tvalues[1:]  # exclude the constant term\n",
    "    p_values = model.pvalues[1:]  # exclude the constant term\n",
    "    critical_value = stats.t.ppf(1 - alpha / 2, model.df_resid)\n",
    "    confidence_intervals = model.conf_int(alpha).iloc[1:]  # exclude the constant term\n",
    "    results = pd.DataFrame({'t_stat': t_stats,\n",
    "                            'p_value': p_values,\n",
    "                            'lower_ci': confidence_intervals[0],\n",
    "                            'upper_ci': confidence_intervals[1]},\n",
    "                           index=feature_names)\n",
    "    return results\n",
    "\n",
    "hypothesis_results = {}\n",
    "for col in Y_df.columns:\n",
    "    X_train = data[feature_names]\n",
    "    y_train = data[col]\n",
    "    hypothesis_results[col] = sm.OLS(y_train, sm.add_constant(X_train)).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "\n",
    "hypothesis_test_results = {}\n",
    "for col, model in hypothesis_results.items():\n",
    "    t_stats = model.tvalues[1:]  # exclude the constant term\n",
    "    p_values = model.pvalues[1:]  # exclude the constant term\n",
    "    confidence_intervals = model.conf_int().iloc[1:]  # exclude the constant term\n",
    "    hypothesis_test_results[col] = pd.DataFrame({'t_stat': t_stats,\n",
    "                                                 'p_value': p_values,\n",
    "                                                 'lower_ci': confidence_intervals[0],\n",
    "                                                 'upper_ci': confidence_intervals[1]},\n",
    "                                                index=feature_names)\n",
    "\n",
    "hypothesis_results_df = pd.concat(hypothesis_test_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4870694-f8ac-4fa4-912a-f34bbf7a3cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hypothesis_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee72d7-f004-45b7-929f-f261409b5840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract the t-statistics\n",
    "t_stats_df = hypothesis_results_df.xs('t_stat', level=1, axis=1)\n",
    "\n",
    "alpha = 0.05\n",
    "min_df_resid = min([results.df_resid for results in hypothesis_results.values()])\n",
    "critical_value = stats.t.ppf(1 - alpha / 2, min_df_resid)\n",
    "\n",
    "t_stats_df = hypothesis_results_df.xs('t_stat', level=1, axis=1)\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(t_stats_df, cmap=\"coolwarm\", annot=True, cbar_kws={'label': 't-statistic'})\n",
    "\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.axhline(y=len(t_stats_df), color='red', linestyle='--')\n",
    "\n",
    "plt.title('T-Statistics for All Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129c309-d7fb-4844-a70e-663bed5a0f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_values_df = hypothesis_results_df.xs('p_value', level=1, axis=1)\n",
    "\n",
    "# Create a boolean DataFrame on the p-value\n",
    "significant_coefficients_df = p_values_df < 0.05\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(significant_coefficients_df, cmap=\"coolwarm\", cbar_kws={'label': 'Significance (True: Significant, False: Not Significant)'})\n",
    "\n",
    "plt.title('Significance of Coefficients (p-value < 0.05)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff3f00-1a58-43dc-a6f3-1e167a8a6418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
