{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70205231-8c98-4c6d-ba0c-f342698fdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reduce display precision on numpy arrays\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "df = pd.read_csv('C:/Users/Computer/Documents/bachelor/dataset.csv')\n",
    "pd.options.mode.chained_assignment=None\n",
    "df['csp'][637:]  = df['csp'][0:638].mean()\n",
    "\n",
    "df['Index'] = pd.to_numeric(df['Index'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59988b4-8716-4a35-975d-3bc3f5d3aeb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb75f66-2bc1-4cdb-8cdd-f05660610ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-30].values\n",
    "Y = df.iloc[:, -30:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cdf3a-e4a6-434c-a462-b76e27ba958d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_names = df.columns[1:18] \n",
    "target_names = df.columns[-30:]  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_df = df[feature_names]\n",
    "Y_df = df[target_names]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_df = pd.DataFrame(scaler.fit_transform(X_df), columns=X_df.columns)\n",
    "\n",
    "data = pd.concat([Y_df, X_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae685ef-43ff-4975-b6ee-9429fe1d8ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd38d1-7998-446c-a080-1197f164c023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extratrees_feature_selection(train, y_key, jobs=24):\n",
    "    X_train = train.drop(y_key, axis=1)\n",
    "    y_train = train[y_key]\n",
    "\n",
    "    extratrees = ExtraTreesRegressor(n_jobs=jobs, random_state=42)\n",
    "    extratrees.fit(X_train, y_train)\n",
    "\n",
    "    selector = SelectFromModel(extratrees, prefit=True)\n",
    "    selected_features = train.drop(y_key, axis=1).columns[selector.get_support()]\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6efe43-d9e3-482f-8af3-b6e2b1da48f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initial_hyperparameter_tuning(train, y_key, selected_features, model_config):\n",
    "    X_train = train[selected_features]\n",
    "    y_train = train[y_key]\n",
    "\n",
    "    time_series_cv = TimeSeriesSplit(n_splits=model_config[\"tscv_splits\"])\n",
    "    \n",
    "    pipeline = Pipeline([(\"svr\", SVR())])\n",
    "    param_grid = {\n",
    "        \"svr__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"svr__C\": [0.1, 1, 10],\n",
    "        \"svr__epsilon\": [0.01, 0.1, 1, 2]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=time_series_cv, scoring=\"neg_mean_squared_error\", n_jobs=24)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a404c-bdf6-4c53-ae7a-f94b8ac74fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def svr_tuned(train, test, y_key, selected_features, best_params):\n",
    "    X_train = train[selected_features]\n",
    "    X_test = test[selected_features]\n",
    "    y_train = train[y_key]\n",
    "\n",
    "    svr_model = SVR(kernel=best_params[y_key][\"svr__kernel\"], C=best_params[y_key][\"svr__C\"], epsilon=best_params[y_key][\"svr__epsilon\"])\n",
    "    svr_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = pd.Series(svr_model.predict(X_test), index=test.index).rename(\"svr_tuned_y_hat\")\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68223aa-0fdd-4c4d-b9b9-7449d8c01264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multioutput_svr_tuned_extratrees(train, test, y_keys, best_params, jobs=24):\n",
    "    preds = {}\n",
    "    for y_key in y_keys:\n",
    "        selected_features = extratrees_feature_selection(train, y_key, jobs)\n",
    "        preds[y_key] = svr_tuned(train, test, y_key, selected_features, best_params)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2f32f-7c95-4a44-a664-1bb8828943a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"tscv_splits\": 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a06322-e6d5-474d-9b24-75fb854af191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_current_values_and_errors():\n",
    "    for col in Y_df.columns:\n",
    "        actuals_no_nan = Actuals[col][train_start_size:].dropna()\n",
    "        forecasts_no_nan = Forecasts[col][train_start_size:].dropna()\n",
    "        forecast_errors_no_nan = Forecast_Errors[col][train_start_size:].dropna()\n",
    "        \n",
    "        print(f\"Actuals for {col}:\\n{actuals_no_nan}\")\n",
    "        print(f\"Forecasts for {col}:\\n{forecasts_no_nan}\")\n",
    "        print(f\"Forecast_Errors for {col}:\\n{forecast_errors_no_nan}\")\n",
    "        \n",
    "        mae = mean_absolute_error(actuals_no_nan, forecasts_no_nan)\n",
    "        mse = mean_squared_error(actuals_no_nan, forecasts_no_nan)\n",
    "        \n",
    "        print(f\"Current MAE for {col}: {mae}\")\n",
    "        print(f\"Current MSE for {col}: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24eec8-82f2-4738-8d88-4a4b6f5a7a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Perform hyperparameter tuning on the initial training set\n",
    "train_start_size = 200\n",
    "initial_train = data.iloc[:train_start_size]\n",
    "\n",
    "initial_selected_features = {}\n",
    "for y_key in Y_df.columns:\n",
    "    initial_selected_features[y_key] = extratrees_feature_selection(initial_train, y_key, jobs=10)\n",
    "    \n",
    "best_params = {}\n",
    "for y_key in Y_df.columns:\n",
    "    best_params[y_key] = initial_hyperparameter_tuning(initial_train, y_key, initial_selected_features[y_key], model_config)\n",
    "\n",
    "# Initialize empty dictionaries to store results\n",
    "Actuals = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Forecasts = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "Forecast_Errors = {col: pd.Series(dtype=float, name=col) for col in Y_df.columns}\n",
    "MAE = {}\n",
    "MSE = {}\n",
    "R2 = {}\n",
    "\n",
    "# Expanding window loop\n",
    "for t in range(train_start_size, len(data) - 1):\n",
    "    train = data.iloc[:t]\n",
    "    test = data.iloc[t : t + 1]\n",
    "\n",
    "    preds = multioutput_svr_tuned_extratrees(train, test, Y_df.columns, best_params, jobs=10)\n",
    "\n",
    "    for col in Y_df.columns:\n",
    "        Forecasts[col] = pd.concat([Forecasts[col], preds[col]])\n",
    "        Actuals[col] = pd.concat([Actuals[col], test[col]])\n",
    "        Forecast_Errors[col] = pd.concat([Forecast_Errors[col], test[col] - preds[col]])\n",
    "\n",
    "    # Print progress every 25 data points\n",
    "    if t % 25 == 0:\n",
    "        print(f\"Progress: {t}/{len(data) - 1}\")\n",
    "\n",
    "# Calculate MAE and MSE for each target variable\n",
    "for col in Y_df.columns:\n",
    "    MAE[col] = mean_absolute_error(Actuals[col], Forecasts[col])\n",
    "    MSE[col] = mean_squared_error(Actuals[col], Forecasts[col])\n",
    "    R2[col] = r2_score(Actuals[col], Forecasts[col])\n",
    "\n",
    "for col in Y_df.columns:\n",
    "    print(f\"Actuals for {col}:\")\n",
    "    print(Actuals[col])\n",
    "    print(f\"Forecasts for {col}:\")\n",
    "    print(Forecasts[col])\n",
    "    print(f\"Forecast Errors for {col}:\")\n",
    "    print(Forecast_Errors[col])\n",
    "    print(f\"Mean Absolute Error for {col}: {MAE[col]}\")\n",
    "    print(f\"Mean Squared Error for {col}: {MSE[col]}\")\n",
    "    print(f\"R-squared for {col}: {R2[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26354a87-6d4c-43a7-8c1f-4959311cd4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68144b86-6379-4486-9a42-4f3819ac52b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "best_params_list = []\n",
    "\n",
    "for y_key in Y_df.columns:\n",
    "    best_params_list.append({'Industry': y_key, 'Best Parameters': best_params[y_key]})\n",
    "\n",
    "best_params_df = pd.DataFrame(best_params_list)\n",
    "\n",
    "print(best_params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb1c6d-c483-4ea0-920a-c3a0cadc8f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934f41c-fad0-4c18-9677-d6002422796b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance_metrics = pd.DataFrame(columns=['Industry', 'MAE', 'MSE', 'R2'])\n",
    "\n",
    "# Populate the DataFrame with the existing performance metrics\n",
    "for i, col in enumerate(Y_df.columns):\n",
    "    performance_metrics.loc[i, 'Industry'] = col\n",
    "    performance_metrics.loc[i, 'MAE'] = MAE[col]\n",
    "    performance_metrics.loc[i, 'MSE'] = MSE[col]\n",
    "    performance_metrics.loc[i, 'R2'] = R2[col]\n",
    "\n",
    "# Calculate the mean across all industries and add it to the DataFrame\n",
    "mean_mae = performance_metrics['MAE'].mean()\n",
    "mean_mse = performance_metrics['MSE'].mean()\n",
    "mean_r2 = performance_metrics['R2'].mean()\n",
    "\n",
    "performance_metrics.loc[len(Y_df.columns), ['Industry', 'MAE', 'MSE', 'R2']] = ['Mean', mean_mae, mean_mse, mean_r2]\n",
    "\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f6b43-9a51-4c42-8587-a935b14370a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dd363-8613-4d75-b2cf-b57c427b905d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Historical_Mean_In_Sample_MSE = {}\n",
    "\n",
    "# Calculate in-sample historical mean forecasts and MSE for each target variable\n",
    "for col in Y_df.columns:\n",
    "    in_sample_data = Y_df.iloc[:train_start_size]  # Use only in-sample data\n",
    "    in_sample_historical_mean = in_sample_data[col].mean()\n",
    "    in_sample_historical_mean_forecast = pd.Series([in_sample_historical_mean] * len(in_sample_data), index=in_sample_data[col].index)\n",
    "    \n",
    "    Historical_Mean_In_Sample_MSE[col] = mean_squared_error(in_sample_data[col], in_sample_historical_mean_forecast)\n",
    "    \n",
    "mean_in_sample_mse = sum(Historical_Mean_In_Sample_MSE.values()) / len(Historical_Mean_In_Sample_MSE)\n",
    "\n",
    "# Create a DataFrame with columns for each performance metric\n",
    "results_df = pd.DataFrame(columns=[\"Historical_Mean_In_Sample_MSE\"])\n",
    "\n",
    "# Populate the DataFrame with in-sample MSE results\n",
    "for col in Y_df.columns:\n",
    "    results_df.loc[col] = [Historical_Mean_In_Sample_MSE[col]]\n",
    "\n",
    "# Calculate and add the mean in-sample MSE to the DataFrame\n",
    "results_df.loc[\"Mean\"] = [mean_in_sample_mse]\n",
    "\n",
    "R2_OS_SVR = {}\n",
    "for col in Y_df.columns:\n",
    "    R2_OS_SVR[col] = 1 - (performance_metrics.set_index(\"Industry\").loc[col, \"MSE\"] / results_df.loc[col, \"Historical_Mean_In_Sample_MSE\"])\n",
    "\n",
    "# Create a DataFrame to store the out-of-sample R-squared results\n",
    "out_of_sample_predictability_df = pd.DataFrame(columns=[\"Industry\", \"R2_OS_SVR\"])\n",
    "\n",
    "# Populate the DataFrame with the out-of-sample R-squared values\n",
    "for i, col in enumerate(Y_df.columns):\n",
    "    out_of_sample_predictability_df.loc[i, \"Industry\"] = col\n",
    "    out_of_sample_predictability_df.loc[i, \"R2_OS_SVR\"] = R2_OS_SVR[col]\n",
    "\n",
    "# Calculate the mean out-of-sample R-squared across all industries and add it to the DataFrame\n",
    "mean_r2_os = out_of_sample_predictability_df[\"R2_OS_SVR\"].mean()\n",
    "out_of_sample_predictability_df.loc[len(Y_df.columns), [\"Industry\", \"R2_OS_SVR\"]] = [\"Mean\", mean_r2_os]\n",
    "\n",
    "# Display the out-of-sample predictability DataFrame\n",
    "print(out_of_sample_predictability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3ef5b-1d3b-4e87-8def-acec5626b476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
